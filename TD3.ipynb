{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID et RANDOM SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des données\n",
    "horses = pd.read_csv('data/horse_clean.csv')\n",
    "\n",
    "# Séparation des données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(horses.drop('surgical_lesion_yes', axis=1), horses['surgical_lesion_yes'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la fonction `GridSearchCV` de `sklearn.model_selection`, déterminer les meilleurs hyperparamètres pour les algorithmes suivants :\n",
    "\n",
    "DecisionTreeClassifier,\n",
    "RandomForestClassifier,\n",
    "GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprendre la question précédente en utilisant la fonction `RandomizedSearchCV` de `sklearn.model_selection`.\n",
    "\n",
    "Comparer les résultats et le temps d'exécution des deux méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "horses = pd.read_csv('data/horse.csv')\n",
    "\n",
    "# suppression des colonnes avec trop de valeurs manquantes & inutiles\n",
    "\n",
    "horses.drop(['surgery', 'hospital_number', 'outcome', 'lesion_1',\n",
    "             'lesion_2', 'lesion_3', 'cp_data'],\n",
    "               axis=1, inplace=True\n",
    "               )\n",
    "\n",
    "\n",
    "horses.dropna(thresh=0.6*len(horses), axis=1, inplace=True)\n",
    "# encodage des variables catégorielles\n",
    "\n",
    "# suppression des lignes avec trop de valeurs manquantes\n",
    "horsesf = pd.get_dummies(horses, drop_first=True)\n",
    "\n",
    "# Séparation des données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    horsesf.drop('surgical_lesion_yes', axis=1),\n",
    "    horsesf['surgical_lesion_yes'],\n",
    "    test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir du dataframe, on va créer un pipeline qui va permettre de faire les transformations suivantes :\n",
    "- Remplacer les valeurs manquantes à l'aide d'un [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "- Entrainer un [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemblez une pipeline à l'aide des fonctions çi-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe notre fichier initial, et on créee nos échantillons d'entrainement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainons notre pipeline sur l'échantillon d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédire les valeurs de l'échantillon de test, et calculer la précision de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline avec GridSearchCV\n",
    "\n",
    "On va maintenant utiliser un GridSearchCV pour trouver les meilleurs paramètres pour notre modèle.\n",
    "\n",
    "On va utiliser les paramètres suivants :\n",
    "Pour le SimpleImputer :\n",
    "- strategy : ['mean', 'median', 'most_frequent']\n",
    "\n",
    "Pour le DecisionTreeClassifier :\n",
    "- max_depth : [3, 10, 20,  30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "0.7073581560283688\n",
      "{'imputer__strategy': 'most_frequent', 'model__max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encore plus de pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant essayer de créer une pipeline pour la totalité des transformations que l'on a faites jusqu'à présent sur nos données.\n",
    "\n",
    "On va donc créer une pipeline qui va :\n",
    "- Retirer les colonnes inutiles\n",
    "- (optionel) Retirer les colonnes avec trop de valeurs manquantes\n",
    "- Imputer les valeurs manquantes\n",
    "- Transformer les variables catégorielles en variables numériques\n",
    "    - Avec une regle pour les variables nominales\n",
    "    - Avec une regle pour les variables ordinales\n",
    "- Entrainer un DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pour faciliter la suite, on peut préciser le type de chaque colonne\n",
    "horses = pd.read_csv('data/horse.csv',\n",
    "            dtype= {'surgery': 'category',\n",
    "                'age': 'category',\n",
    "                'hospital_number': 'int64',\n",
    "                'rectal_temp': 'float64',\n",
    "                'pulse': 'float64',\n",
    "                'respiratory_rate': 'float64',\n",
    "                'temp_of_extremities': 'category',\n",
    "                'peripheral_pulse': 'category',\n",
    "                'mucous_membrane': 'category',\n",
    "                'capillary_refill_time': 'category',\n",
    "                'pain': 'category',\n",
    "                'peristalsis': 'category',\n",
    "                'abdominal_distention': 'category',\n",
    "                'nasogastric_tube': 'category',\n",
    "                'nasogastric_reflux': 'category',\n",
    "                'nasogastric_reflux_ph': 'float64',\n",
    "                'rectal_exam_feces': 'category',\n",
    "                'abdomen': 'category',\n",
    "                'packed_cell_volume': 'float64',\n",
    "                'total_protein': 'float64',\n",
    "                'abdomo_appearance': 'category',\n",
    "                'abdomo_protein': 'float64',\n",
    "                'outcome': 'category',\n",
    "                'surgical_lesion': 'category',\n",
    "                'lesion_1': 'category',\n",
    "                'lesion_2': 'category',\n",
    "                'lesion_3': 'category',\n",
    "                'cp_data': 'category'\n",
    "                }\n",
    "            )\n",
    "\n",
    "# echantillons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparation des données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    horses.drop('surgical_lesion', axis=1),\n",
    "    horses['surgical_lesion'],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "y_train = pd.Series([1 if x == 'yes' else 0 for x in y_train])\n",
    "y_test = pd.Series([1 if x == 'yes' else 0 for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
